Deepfakes pose a growing threat to the integrity of visual media, motivating detectors that remain reliable as forgeries become increasingly realistic. We propose a deepfake detection framework built on CLIP-derived SigLIP-2 vision transformers and a multi-task design that jointly performs (i) classification and (ii) manipulated-region localization when pix-el-level supervision is available. We evaluate the approach on three public benchmarks of increasing complexity—HiDF, SID_Set (SIDA), and CiFake—using each dataset’s official partitions where provided (SID_Set uses the predefined train/validation split) and a standardized preprocessing and training pipeline across experiments. On HiDF, our model achieves strong performance on both video and image tracks (AUC up to 0.931 on video and 0.968 on images), yielding large gains relative to previously reported HiDF baselines under their published settings. On SID_Set, the model reaches 99.1% three-class accuracy (real / synthetic / tampered) and produces accurate localization masks for many tampered regions, while we explicitly document the split protocol and leakage checks to support the validity of the evaluation. On CiFake, the model exceeds 95% accuracy and attains an AUC of 0.986. Overall, the results indicate that SigLIP-2 representations com-bined with multi-task training can deliver high detection accuracy and interpretable lo-calization on challenging, realistic forgeries, while highlighting the importance of clearly stated evaluation protocols for fair comparison.


"For the full multi-task SigLIP-2 results reported in the paper (Section 3.2), please refer to siglip2siddataset.py. The other scripts provide optimized binary classification for specific benchmarks."
